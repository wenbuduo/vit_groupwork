# Vision Transformer (ViT) å¤ç°æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
2. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
3. [ä»é›¶å®ç°](#ä»é›¶å®ç°)
4. [è®­ç»ƒè‡ªå·±çš„æ¨¡å‹](#è®­ç»ƒè‡ªå·±çš„æ¨¡å‹)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ”§ ç¯å¢ƒé…ç½®

### æ–¹æ³•1: ä½¿ç”¨condaï¼ˆæ¨èï¼‰
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n vit python=3.9
conda activate vit

# å®‰è£…PyTorchï¼ˆæ ¹æ®ä½ çš„CUDAç‰ˆæœ¬é€‰æ‹©ï¼‰
# CPUç‰ˆæœ¬
conda install pytorch torchvision torchaudio cpuonly -c pytorch

# GPUç‰ˆæœ¬ (CUDA 11.8)
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# å®‰è£…å…¶ä»–ä¾èµ–
pip install transformers pillow requests tqdm
```

### æ–¹æ³•2: ä½¿ç”¨pip
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv vit_env
source vit_env/bin/activate  # Linux/Mac
# vit_env\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install torch torchvision transformers pillow requests tqdm
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿè·‘é€šï¼‰

### æ–¹æ¡ˆA: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ¨ç†ï¼ˆæœ€ç®€å•ï¼‰

```bash
python vit_quickstart.py
```

**è¿™ä¸ªè„šæœ¬ä¼šï¼š**
- è‡ªåŠ¨ä¸‹è½½é¢„è®­ç»ƒçš„ViTæ¨¡å‹
- ä¸‹è½½æµ‹è¯•å›¾ç‰‡
- è¿›è¡Œå›¾åƒåˆ†ç±»
- è¾“å‡ºTop-5é¢„æµ‹ç»“æœ

**ç¤ºä¾‹è¾“å‡ºï¼š**
```
æ­£åœ¨åŠ è½½ViTæ¨¡å‹...
æ­£åœ¨è¿›è¡Œæ¨ç†...
é¢„æµ‹ç±»åˆ«ID: 281
é¢„æµ‹ç±»åˆ«: tabby cat

Top-5 é¢„æµ‹ç»“æœ:
1. tabby cat: 0.4123
2. Egyptian cat: 0.3456
3. tiger cat: 0.1234
...
```

---

## ğŸ”¨ ä»é›¶å®ç°ViTæ¶æ„

### æ–¹æ¡ˆB: ç†è§£å¹¶æµ‹è¯•ViTæ¶æ„

```bash
python vit_from_scratch.py
```

**è¿™ä¸ªè„šæœ¬åŒ…å«ï¼š**
- âœ… Patch Embeddingå±‚
- âœ… Multi-Head Self-Attention
- âœ… Transformer Encoder Block
- âœ… å®Œæ•´çš„ViTæ¨¡å‹
- âœ… ä¸‰ç§æ¨¡å‹å¤§å°ï¼šTiny/Small/Base

**ä»£ç ç»“æ„ï¼š**
```
VisionTransformer
â”œâ”€â”€ PatchEmbedding      # å›¾åƒåˆ‡åˆ†ä¸ºpatches
â”œâ”€â”€ TransformerBlock    # Transformerç¼–ç å™¨
â”‚   â”œâ”€â”€ MultiHeadAttention
â”‚   â””â”€â”€ MLP
â””â”€â”€ Classification Head # åˆ†ç±»å±‚
```

**æ¨¡å‹å‚æ•°å¯¹æ¯”ï¼š**
| æ¨¡å‹ | å‚æ•°é‡ | é€‚ç”¨åœºæ™¯ |
|------|--------|----------|
| ViT-Tiny | ~5M | å¿«é€Ÿå®éªŒ |
| ViT-Small | ~22M | ä¸­ç­‰æ•°æ®é›† |
| ViT-Base | ~86M | å¤§è§„æ¨¡è®­ç»ƒ |

---

## ğŸ‹ï¸ è®­ç»ƒè‡ªå·±çš„æ¨¡å‹

### æ–¹æ¡ˆC: åœ¨CIFAR-10ä¸Šä»å¤´è®­ç»ƒ

```bash
# è®­ç»ƒViT-Tinyæ¨¡å‹
python train_vit_cifar10.py
```

**è®­ç»ƒé…ç½®ï¼š**
- æ•°æ®é›†: CIFAR-10 (60,000å¼ å›¾ç‰‡, 10ç±»)
- æ¨¡å‹: ViT-Tiny
- è®­ç»ƒè½®æ•°: 50 epochs
- æ‰¹æ¬¡å¤§å°: 64
- å­¦ä¹ ç‡: 0.001 (cosine decay)

**é¢„æœŸç»“æœï¼š**
- è®­ç»ƒæ—¶é—´: ~2å°æ—¶ (GPU) / ~10å°æ—¶ (CPU)
- éªŒè¯å‡†ç¡®ç‡: 70-75% (ViT-Tiny)

**æç¤ºï¼š** å¦‚æœGPUå†…å­˜ä¸è¶³ï¼Œå¯ä»¥ï¼š
1. å‡å°batch_size
2. ä½¿ç”¨æ›´å°çš„å›¾åƒå°ºå¯¸
3. å‡å°‘æ¨¡å‹æ·±åº¦

### æ–¹æ¡ˆD: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒï¼ˆæ¨èï¼‰

```bash
# å¾®è°ƒé¢„è®­ç»ƒViTæ¨¡å‹
python finetune_vit.py
```

**ä¼˜åŠ¿ï¼š**
- âœ… æ”¶æ•›æ›´å¿«
- âœ… å‡†ç¡®ç‡æ›´é«˜
- âœ… éœ€è¦æ›´å°‘æ•°æ®
- âœ… è®­ç»ƒæ—¶é—´æ›´çŸ­

**å¾®è°ƒç­–ç•¥ï¼š**
1. **å†»ç»“backboneï¼Œåªè®­ç»ƒåˆ†ç±»å¤´**ï¼ˆæœ€å¿«ï¼‰
   - è®­ç»ƒæ—¶é—´: ~30åˆ†é’Ÿ
   - é€‚åˆå°æ•°æ®é›†
   
2. **è§£å†»æ‰€æœ‰å±‚**ï¼ˆæœ€å¥½æ•ˆæœï¼‰
   - è®­ç»ƒæ—¶é—´: ~2å°æ—¶
   - éœ€è¦æ›´å¤šæ•°æ®

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### ä¸åŒæ–¹æ¡ˆçš„å¯¹æ¯”

| æ–¹æ¡ˆ | å‡†ç¡®ç‡ | è®­ç»ƒæ—¶é—´ | éš¾åº¦ | æ¨èæŒ‡æ•° |
|------|--------|----------|------|----------|
| é¢„è®­ç»ƒæ¨ç† | - | 0åˆ†é’Ÿ | â­ | â­â­â­â­â­ |
| ä»é›¶è®­ç»ƒ(Tiny) | 70-75% | 2å°æ—¶ | â­â­â­ | â­â­â­ |
| ä»é›¶è®­ç»ƒ(Base) | 80-85% | 8å°æ—¶ | â­â­â­â­ | â­â­ |
| é¢„è®­ç»ƒå¾®è°ƒ | 85-90% | 30åˆ†é’Ÿ | â­â­ | â­â­â­â­â­ |

---

## ğŸ¯ ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†

### å‡†å¤‡æ•°æ®é›†
```
your_dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ class1/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â””â”€â”€ img2.jpg
â”‚   â””â”€â”€ class2/
â”‚       â”œâ”€â”€ img1.jpg
â”‚       â””â”€â”€ img2.jpg
â””â”€â”€ val/
    â”œâ”€â”€ class1/
    â””â”€â”€ class2/
```

### ä¿®æ”¹ä»£ç 
```python
# åœ¨ finetune_vit.py ä¸­ä¿®æ”¹ï¼š
train_dataset = datasets.ImageFolder(
    root='your_dataset/train',
    transform=transform_train
)

val_dataset = datasets.ImageFolder(
    root='your_dataset/val',
    transform=transform_val
)
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: GPUå†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
**A:** å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š
```python
# 1. å‡å°æ‰¹æ¬¡å¤§å°
BATCH_SIZE = 32  # æ”¹ä¸º 16 æˆ– 8

# 2. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 4
loss = loss / accumulation_steps
loss.backward()
if (step + 1) % accumulation_steps == 0:
    optimizer.step()
    optimizer.zero_grad()

# 3. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()
```

### Q2: è®­ç»ƒé€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ
**A:** ä¼˜åŒ–å»ºè®®ï¼š
- ä½¿ç”¨å¤šGPUè®­ç»ƒï¼š`torch.nn.DataParallel`
- å¢åŠ num_workersï¼š`DataLoader(..., num_workers=4)`
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼šViT-Tinyä»£æ›¿ViT-Base
- ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ

### Q3: å‡†ç¡®ç‡ä¸é«˜æ€ä¹ˆåŠï¼Ÿ
**A:** æ”¹è¿›æ–¹æ³•ï¼š
1. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
2. å¢åŠ æ•°æ®å¢å¼º
3. è°ƒæ•´å­¦ä¹ ç‡
4. è®­ç»ƒæ›´å¤šepochs
5. ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹

### Q4: å¦‚ä½•å¯è§†åŒ–æ³¨æ„åŠ›å›¾ï¼Ÿ
**A:** æ·»åŠ ä»¥ä¸‹ä»£ç ï¼š
```python
# è·å–æ³¨æ„åŠ›æƒé‡
attention_weights = model.vit.encoder.layer[-1].attention.self.attention_probs
# å¯è§†åŒ–ï¼ˆéœ€è¦å®‰è£…matplotlibï¼‰
import matplotlib.pyplot as plt
plt.imshow(attention_weights[0, 0].detach().cpu())
plt.show()
```

---

## ğŸ“š è¿›é˜¶é˜…è¯»

### åŸå§‹è®ºæ–‡
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)

### ç›¸å…³èµ„æº
- HuggingFace ViTæ–‡æ¡£: https://huggingface.co/docs/transformers/model_doc/vit
- PyTorch Image Models: https://github.com/rwightman/pytorch-image-models
- è®ºæ–‡è§£è¯»è§†é¢‘: [æ¨èæœç´¢ç›¸å…³è§†é¢‘]

---

## ğŸ‰ æ€»ç»“

### æ¨èå­¦ä¹ è·¯å¾„ï¼š

1. **ç¬¬ä¸€æ­¥ï¼šå¿«é€Ÿä½“éªŒ**
   - è¿è¡Œ `vit_quickstart.py`
   - æ„Ÿå—ViTçš„æ¨ç†æ•ˆæœ

2. **ç¬¬äºŒæ­¥ï¼šç†è§£åŸç†**
   - é˜…è¯» `vit_from_scratch.py`
   - ç†è§£å„ä¸ªç»„ä»¶çš„ä½œç”¨

3. **ç¬¬ä¸‰æ­¥ï¼šå®æˆ˜è®­ç»ƒ**
   - è¿è¡Œ `finetune_vit.py`
   - åœ¨è‡ªå·±çš„æ•°æ®ä¸Šå¾®è°ƒ

4. **ç¬¬å››æ­¥ï¼šæ·±å…¥ç ”ç©¶**
   - é˜…è¯»åŸå§‹è®ºæ–‡
   - å°è¯•æ”¹è¿›æ¨¡å‹æ¶æ„

### ä¸‹ä¸€æ­¥å¯ä»¥åšä»€ä¹ˆï¼Ÿ

- ğŸ” ç ”ç©¶å…¶ä»–ViTå˜ä½“ï¼šDeiT, Swin Transformer
- ğŸ¨ å°è¯•Vision-Languageæ¨¡å‹ï¼šCLIP, BLIP
- ğŸš€ ä¼˜åŒ–æ¨¡å‹ï¼šå‰ªæã€é‡åŒ–ã€è’¸é¦
- ğŸ“± éƒ¨ç½²æ¨¡å‹ï¼šONNXå¯¼å‡ºã€ç§»åŠ¨ç«¯éƒ¨ç½²

---

## ğŸ’¡ æç¤º

- å»ºè®®ä»**é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ**å¼€å§‹ï¼Œè¿™æ˜¯æœ€é«˜æ•ˆçš„æ–¹å¼
- ä»å¤´è®­ç»ƒéœ€è¦å¤§é‡æ•°æ®å’Œè®¡ç®—èµ„æº
- ViTåœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¡¨ç°æœ€å¥½
- å¯¹äºå°æ•°æ®é›†ï¼ŒCNNå¯èƒ½è¡¨ç°æ›´å¥½

ç¥ä½ å¤ç°é¡ºåˆ©ï¼ğŸŠ
